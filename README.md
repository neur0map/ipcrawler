# üï∑Ô∏è IPCrawler

> *A reconnaissance automation tool built for CTF and penetration testing by a cybersecurity engineer learning Rust, powered entirely by AI pair programming*

<div align="center">

![License](https://img.shields.io/badge/license-MIT-blue.svg)
![Language](https://img.shields.io/badge/language-Rust-orange.svg)
![Status](https://img.shields.io/badge/status-Active%20Development-green.svg)

**üöÄ Real-time TUI ‚Ä¢ üîç Reconnaissance automation ‚Ä¢ ‚ö° Concurrent scanning**

[Discord Server](https://discord.gg/ipcrawler) ‚Ä¢ [Reddit Community](https://reddit.com/r/ipcrawler) ‚Ä¢ [Report Issues](https://github.com/ipcrawler/ipcrawler/issues)

</div>

---

## üìñ About This Project

Hi! I'm Carlos, a cybersecurity and networking engineer. While I'm not a programmer by trade, I built this tool entirely with [**Claude Code**](https://claude.ai/code) - an AI pair programming assistant. As someone who spends time on Hack The Box and CTF challenges, I was frustrated with complex tools like [AutoRecon](https://github.com/Tib3rius/AutoRecon) that are hard to set up and customize.

Since the security industry seems to be moving from C to Rust, I decided this would be a perfect opportunity to learn Rust while building something actually useful for my workflow. Every line of code, every feature, and every bug fix has been implemented through careful collaboration with AI - and honestly, I've learned a ton about programming in the process!

**‚ö†Ô∏è Full transparency:** As I'm not an experienced programmer, there might be bugs or issues. I welcome anyone to try the tool and submit issues - I'll review them and work on improvements with my AI coding partner.

---

## ‚ú® What IPCrawler Does

IPCrawler is a **comprehensive reconnaissance automation tool** designed for cybersecurity professionals and enthusiasts. It combines DNS enumeration, host discovery, port scanning, and web application analysis into a unified workflow with real-time visual feedback.

### üéØ Built For
- **Penetration testing** engagements and security assessments
- **Hack The Box** challenges and OSCP lab practice
- **CTF competitions** requiring rapid reconnaissance
- **Bug bounty hunting** and responsible disclosure programs
- **Network security audits** with immediate results

### üõ†Ô∏è Core Capabilities
- **Multi-phase reconnaissance**: DNS ‚Üí Host Discovery ‚Üí Port Scanning ‚Üí Service Analysis
- **Real-time TUI**: Live progress tracking with colored results and system monitoring
- **Parallel processing**: Concurrent execution across all reconnaissance phases
- **Web application analysis**: Directory enumeration and file discovery on HTTP/HTTPS services
- **Smart target handling**: IPv4/IPv6 addresses, domains, and CIDR ranges
- **Performance optimized**: 2-minute time budgets per service for rapid CTF/lab workflows
- **Comprehensive coverage**: DNS records, host enumeration, port discovery, and web content analysis
- **Professional artifacts**: Timestamped results with multiple output formats (TXT/MD/JSON)

---

## üöÄ Quick Start

### Installation
```bash
# Clone and build
git clone https://github.com/ipcrawler/ipcrawler.git
cd ipcrawler
make build

# The build process will:
# ‚úÖ Compile the binary
# ‚úÖ Create ~/.local/bin/ipcrawler symlink  
# ‚úÖ Install global.toml config
```

### Basic Usage
```bash
# Scan a domain
ipcrawler -t google.com

# Scan with verbose logging  
ipcrawler -t 8.8.8.8 --verbose

# Get help
ipcrawler --help
```

### Requirements
- **DNS Tools**: `nslookup` and `dig` in PATH (core reconnaissance)
- **Port Scanner**: `rustscan` and `nmap` (optional, for comprehensive coverage)
- **Host Discovery**: `dnsx` and `httpx` (optional, for subdomain enumeration)
- **Web Analysis**: `feroxbuster`, `katana`, `cewl` (optional, for HTTP/HTTPS services)
- **Terminal**: Minimum 70x20 characters for TUI
- **File descriptors**: ‚â•2048 (`ulimit -n 2048`) for concurrent operations

---

## üéÆ Interface Preview

```
‚îå‚îÄ IPCrawler ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ Target: example.com | Status: Running | Elapsed: 00:02.8s               ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
‚îå‚îÄ System ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ CPU: 18.7% | RAM: 12.4GB/16.0GB | FDs: 127/2048                         ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
‚îå‚îÄ Scan Progress ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ Active Tasks ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ Phase 3: Service Probing     ‚îÇ ‚úì nslookup: Found 8 DNS records           ‚îÇ
‚îÇ ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñë‚ñë‚ñë‚ñë 85% ‚îÇ ‚úì dig: Found 12 DNS records               ‚îÇ
‚îÇ                              ‚îÇ ‚úì hosts_discovery: Found 3 subdomains     ‚îÇ
‚îÇ 17/20 tasks completed        ‚îÇ ‚óØ looter [89s]: Analyzing web services    ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
‚îå‚îÄ Tabs (‚Üê‚Üí to switch) ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ [Overview] [Ports] [Services] [Logs] [Help]                             ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
‚îå‚îÄ Discovered Services ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ Live Logs ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ 80/tcp  http   example.com   ‚îÇ 14:23:15 INF ‚úì port_scanner: Found 6 ports ‚îÇ
‚îÇ 443/tcp https  example.com   ‚îÇ 14:23:16 INF ‚úì looter: Phase B - Baseline  ‚îÇ
‚îÇ 53/tcp  domain example.com   ‚îÇ 14:23:18 INF ‚úì looter: Found /admin.php    ‚îÇ
‚îÇ 22/tcp  ssh    example.com   ‚îÇ 14:23:19 INF ‚úì looter: Found /config.bak   ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

---

## ‚öôÔ∏è Configuration

IPCrawler uses **smart defaults** - everything works out of the box, but cybersecurity professionals can customize for their specific use cases:

```toml
# ~/.config/ipcrawler/global.toml
# Uncomment sections to override defaults

[concurrency]
max_total_scans = 50          # Total concurrent operations 
max_port_scans = 10          # Port scanning pool size
max_service_scans = 20       # Service analysis parallelism

# [tools.port_scanner.ports]
# scan_strategy = "top-1000"   # Port selection strategy
# # Options: "top-100", "top-1000", "top-10000", "full", "custom"

# [tools.port_scanner.rustscan]
# timeout_ms = 1500           # Fast port discovery
# batch_size = 2000           # Ports per batch

# [tools.port_scanner.nmap]  
# version_intensity = 4       # Service detection depth (0-9)
# total_timeout_ms = 90000    # 90 seconds for service analysis

# [tools.hosts_discovery]
# target_ip = "127.0.0.1"     # Map discovered domains to this IP
# auto_write = true           # Update /etc/hosts if sudo available
```

**Performance Note**: The looter plugin uses internal time budgets (2 minutes per service) optimized for CTF and lab environments. All reconnaissance phases run in parallel for maximum efficiency.

---

## üìÅ Output Structure

Professional artifacts for documentation and analysis:

```
artifacts/runs/run_example.com_20250828_142015/
‚îú‚îÄ‚îÄ scans/
‚îÇ   ‚îú‚îÄ‚îÄ nslookup_results.txt      # DNS enumeration results
‚îÇ   ‚îú‚îÄ‚îÄ dig_results.txt           # DNS query outputs  
‚îÇ   ‚îú‚îÄ‚îÄ port_scanner_results.txt  # Port discovery and service detection
‚îÇ   ‚îú‚îÄ‚îÄ hosts_discovery_results.txt # Subdomain and virtual host enumeration
‚îÇ   ‚îî‚îÄ‚îÄ looter_results.txt        # Web application analysis findings
‚îú‚îÄ‚îÄ reports/
‚îÇ   ‚îú‚îÄ‚îÄ summary.txt               # Executive summary for reports
‚îÇ   ‚îú‚îÄ‚îÄ summary.md                # Technical documentation
‚îÇ   ‚îî‚îÄ‚îÄ summary.json              # Machine-readable data for tooling
‚îî‚îÄ‚îÄ artifacts/
    ‚îú‚îÄ‚îÄ discovered_files/         # Retrieved web content and configs
    ‚îú‚îÄ‚îÄ wordlists/               # Generated target-specific wordlists  
    ‚îî‚îÄ‚îÄ screenshots/             # Visual evidence (future feature)
```

---

## üó∫Ô∏è Roadmap & Current Status

### ‚úÖ **Current Capabilities** (v0.1.0-alpha)
- ‚úÖ **DNS enumeration** with nslookup and dig integration
- ‚úÖ **Host discovery** using dnsx and httpx for subdomain/vhost enumeration
- ‚úÖ **Port scanning** with RustScan + Nmap two-phase discovery
- ‚úÖ **Web application analysis** with directory enumeration and file discovery
- ‚úÖ **Parallel processing** across all reconnaissance phases
- ‚úÖ **Real-time TUI** with live progress and system monitoring

### üöß **In Development**
- üîí **SSL/TLS certificate analysis** and vulnerability assessment
- üì∑ **Screenshot capture** for HTTP/HTTPS services  
- üß¨ **Advanced payload generation** and mutation strategies
- üéØ **Target scope management** for large engagements

### üìã **Planned Features**
- üåê **API endpoint discovery** and analysis
- üóÉÔ∏è **Database service probing** (MySQL, PostgreSQL, MongoDB)
- üìß **Email enumeration** and OSINT integration
- üîß **Custom plugin development** framework
- üìä **Advanced reporting** with executive summaries

*Contributing to penetration testing automation - one plugin at a time!*

---

## ü§ù Community & Support

### Get Help
- üí¨ **[Discord Server](https://discord.gg/ipcrawler)** - Chat with users and get help
- üìñ **[Reddit Community](https://reddit.com/r/ipcrawler)** - Discussions and tips
- üêõ **[GitHub Issues](https://github.com/ipcrawler/ipcrawler/issues)** - Bug reports and feature requests

### Contributing
While I'm still learning programming, I'm happy to review:
- üêõ Bug reports with detailed reproduction steps
- üí° Feature suggestions and use cases
- üìù Documentation improvements
- üß™ Testing on different systems

---

## üîß Troubleshooting

### File Descriptor Limit
```bash
# Quick fix (current session)
ulimit -n 2048

# Permanent fix - add to ~/.zshrc or ~/.bashrc  
echo "ulimit -n 2048" >> ~/.zshrc
```

### Terminal Size Issues
Ensure your terminal is at least **70x20 characters**. The TUI will warn you if it's too small.

### Tool Installation
```bash
# Core DNS tools (required)
which nslookup dig

# macOS (via Homebrew)
brew install bind

# Ubuntu/Debian  
sudo apt install dnsutils

# Optional reconnaissance tools (for full functionality)
# Port scanning
cargo install rustscan
sudo apt install nmap

# Host discovery  
go install -v github.com/projectdiscovery/dnsx/cmd/dnsx@latest
go install -v github.com/projectdiscovery/httpx/cmd/httpx@latest

# Web analysis
cargo install feroxbuster
go install -v github.com/projectdiscovery/katana/cmd/katana@latest
apt install cewl
```

---

## üìÑ License

MIT License - feel free to use, modify, and learn from this code.

---

## üôè Acknowledgments

- **[Claude Code](https://claude.ai/code)** - The AI pair programming assistant that made this possible
- **[AutoRecon](https://github.com/Tib3rius/AutoRecon)** - Inspiration for building a better alternative
- **The Rust Community** - For creating such an amazing language and ecosystem
- **CTF/HTB Community** - For providing the challenges that drive tool development

---

<div align="center">
<i>Built with ‚ù§Ô∏è and lots of AI assistance by a cybersecurity engineer learning to code</i>
</div>